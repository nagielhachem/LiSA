{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import time\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import process as p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getmyData(filepath):\n",
    "  l = p.getData(filepath)\n",
    "  l = l[1:]\n",
    "  np.random.shuffle(l)\n",
    "  lgt = len(l)\n",
    "  ltrain = l[:int(lgt * 0.8)]\n",
    "  ltest = l[int(lgt * 0.8):]\n",
    "  Y_train = ltrain[:,0]\n",
    "  Y_train = np.array([int(e) for e in Y_train])\n",
    "  X_train = ltrain[:,1]\n",
    "  Y_test = ltest[:,0]\n",
    "  Y_test = np.array([int(e) for e in Y_test])\n",
    "  X_test = ltest[:,1]\n",
    "  return (X_train, Y_train,X_test,Y_test)\n",
    "\n",
    "def autolabels(rects, ax, time = False):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        if (time):\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                    '%f' % float(height) + \"s\",\n",
    "                  ha='center', va='bottom')\n",
    "        else:\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                    '%d' % int(height * 100) + \"%\",\n",
    "                  ha='center', va='bottom')\n",
    "from pylab import rcParams\n",
    "def plot_result(clfs, results):\n",
    "    N = len(clfs)\n",
    "    ind = np.arange(N)  # the x locations for the groups\n",
    "    width = 0.18    # the width of the bars\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(ind , results[:,0], width, color='g')\n",
    "    rects2 = ax.bar(ind - width, results[:,1], width, color='r')\n",
    "    rects3 = ax.bar(ind + width, results[:,2], width, color='b')\n",
    "    rects4 = ax.bar(ind + 2 * width, results[:,3], width, color='y')\n",
    "# add some text for labels, title and axes ticks\n",
    "    ax.set_ylim(0,1.4)\n",
    "    ax.set_ylabel('Pourcentage %')\n",
    "    ax.set_title(\"Benchmark\")\n",
    "    ax.set_xticks(ind )\n",
    "    ax.set_xticks(ind )\n",
    "    labels = [clfs[i][1] for i in range(N)]\n",
    "    ax.set_xticklabels(labels, rotation = 'vertical')\n",
    "    ax.legend((rects1[0], rects2[0], rects3[0], rects4[0]), ('precision', 'recall', 'accuracy','F1 score'))\n",
    "    \n",
    "    autolabels(rects1, ax)\n",
    "    autolabels(rects2, ax)\n",
    "    autolabels(rects3, ax)\n",
    "    autolabels(rects4, ax)\n",
    "    rcParams['figure.figsize'] = (15,15)\n",
    "\n",
    "    plt.show()    \n",
    "    \n",
    "\n",
    "\n",
    "def plot_time_exec(clfs, time_exec):\n",
    "    N = len(clfs)\n",
    "    ind = np.arange(N)  # the x locations for the groups\n",
    "    width = 0.6    # the width of the bars\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(ind , time_exec, width, color='b')\n",
    "# add some text for labels, title and axes ticks\n",
    "    ax.set_ylim(0,time_exec.max() * 1.2)\n",
    "    ax.set_ylabel('time in s')\n",
    "    ax.set_title(\"Benchmark time\")\n",
    "    ax.set_xticks(ind )\n",
    "    ax.set_xticks(ind )\n",
    "    labels = [clfs[i][1] for i in range(N)]\n",
    "    ax.set_xticklabels(labels, rotation = 'vertical')\n",
    "   # ax.legend(rects1[0], 'time in s')\n",
    "    autolabels(rects1, ax, time = True)\n",
    "    rcParams['figure.figsize'] = (15,15)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def classify(clf, data_train, train_labels, data_test, test_labels, ngrams = (1,1), binn = False, idf = True, sparse = True):\n",
    "  t0 = time.time()\n",
    "  if (binn == True):\n",
    "    idf = False\n",
    "  vec = TfidfVectorizer(use_idf = idf, binary = binn, ngram_range = ngrams )\n",
    "  X_train_tfidf = vec.fit_transform(data_train) \n",
    "  X_test_tfidf =  vec.transform(data_test)\n",
    "  if (not(sparse)):\n",
    "      X_train_tfidf = X_train_tfidf.toarray()\n",
    "      X_test_tfidf =  X_test_tfidf.toarray()\n",
    "  clf.fit(X_train_tfidf,train_labels)\n",
    "  predicted = clf.predict(X_test_tfidf)\n",
    "  \n",
    "  #print(pred)\n",
    "  #print(test_labels)\n",
    "  \n",
    "  acc = metrics.accuracy_score(test_labels, predicted)\n",
    "  recall = metrics.recall_score(test_labels, predicted)\n",
    "  pre = metrics.precision_score(test_labels, predicted)\n",
    "  F1 = 2 * (pre * recall) / (pre + recall)\n",
    "  dur = time.time() - t0\n",
    "  return (pre, recall, acc, F1, dur)\n",
    "\n",
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench():\n",
    "    #clf = (GaussianNB(), \"Naive Bayes\")\n",
    "    \n",
    "    clfs = [\n",
    "        (LinearSVC(random_state=0), 'SVM'),\n",
    "        (LogisticRegression(), 'Max Entropy'),\n",
    "        (MultinomialNB(alpha=.01), \"Multinomial NB\"),\n",
    "        (BernoulliNB(alpha=.01), \"BernoulliNB\"),\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(max_iter=50), \"Perceptron\"), \n",
    "        (PassiveAggressiveClassifier(max_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")]\n",
    "    results = []\n",
    "    filepath = 'file2.csv'\n",
    "    X_tr,Y_tr,X_te,Y_te = getmyData(filepath)\n",
    "    for clf, name in clfs:\n",
    "        results.append(classify(clf, X_tr, Y_tr, X_te, Y_te, binn = False))\n",
    "    \n",
    "    results = np.array(results)\n",
    "    plot_result(clfs, results)\n",
    "    plot_time_exec(clfs, results[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.bench>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
