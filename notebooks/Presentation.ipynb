{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Présentation des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir trouvé et implémenté les différentes méthodes de classification et d'analyse du sentiment autour d'une phrase, nous avons pu effectuer des tests de précision et de recall sur un ensemble de donnée pré labélisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultat de précision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.feature_extraction.text as skl_txt\n",
    "import sklearn.linear_model as skl_lm\n",
    "import sklearn.neighbors as skl_nei\n",
    "import sklearn.ensemble as skl_en\n",
    "import sklearn.naive_bayes as skl_nb\n",
    "import sklearn.svm as skl_svm\n",
    "\n",
    "from sklearn import metrics as skl_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/data_cleaned/labelised/\"\n",
    "img_dir = \"../benchmarks/\"\n",
    "\n",
    "path_hutto = data_dir + \"hutto.txt\"\n",
    "path_airline = data_dir + \"airline.txt\"\n",
    "path_kaggle = data_dir + \"kaggle.txt\"\n",
    "path_michigan = data_dir + \"michigan.txt\"\n",
    "path_rtneg = data_dir + \"rt-polarity-neg.txt\"\n",
    "path_rtpos = data_dir + \"rt-polarity-pos.txt\"\n",
    "\n",
    "data_files = {\n",
    "    \"hutto\" : path_hutto, \n",
    "    \"airline\" : path_airline, \n",
    "    \"kaggle\" : path_kaggle, \n",
    "    \"michigan\" : path_michigan, \n",
    "#    \"rt-polarity-neg\" : path_rtneg, \n",
    "#    \"rt-polarity-pos\" : path_rtpos\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = (1,1)\n",
    "binn = False\n",
    "idf = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(file_path):\n",
    "    f = open(file_path, \"r\")\n",
    "    file_data = json.loads(f.readlines()[0])\n",
    "    f.close()\n",
    "    return np.array(file_data)\n",
    "\n",
    "def vectorize_data(text_data, ngrams, binn, idf):\n",
    "    if (binn == True):\n",
    "        idf = False\n",
    "    vectorizer = skl_txt.TfidfVectorizer(use_idf = idf, binary = binn, ngram_range = ngrams)\n",
    "    return vectorizer.fit_transform(text_data) \n",
    "\n",
    "def parse_data(file_data):\n",
    "    data, labels = file_data[:, 1], np.array(file_data[:, 0], dtype='int')\n",
    "    data = vectorize_data(data, ngrams, binn, idf)\n",
    "    return partition_data(data, labels)\n",
    "\n",
    "def partition_data(data, labels, ratio = 0.7):\n",
    "    N = int(ratio * data.shape[0])\n",
    "    idx = np.random.permutation(data.shape[0])\n",
    "    train_data = data[idx[:N]]\n",
    "    train_labels = labels[idx[:N]]\n",
    "    test_data = data[idx[N:]]\n",
    "    test_labels = labels[idx[N:]]\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "def get_data(files):\n",
    "    data = {}\n",
    "    for key in files:\n",
    "        file_data = parse_file(files[key])\n",
    "        tr_data, tr_labels, te_data, te_labels = parse_data(file_data)\n",
    "        partitioned_data = {\n",
    "            'train_data': tr_data,\n",
    "            'train_labels' : tr_labels,\n",
    "            'test_data': te_data,\n",
    "            'test_labels' : te_labels\n",
    "        }\n",
    "        data[key] = partitioned_data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(test_labels, predicted_labels):\n",
    "    acc = skl_metrics.accuracy_score(test_labels, predicted_labels)\n",
    "    recall = skl_metrics.recall_score(test_labels, predicted_labels)\n",
    "    pre = skl_metrics.precision_score(test_labels, predicted_labels)\n",
    "    F1 = 2 * (pre * recall) / (pre + recall)\n",
    "    return pre, recall, acc, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_performance(clf, data_train, train_labels, data_test, test_labels):\n",
    "    t = time.time()\n",
    "    clf.fit(data_train, train_labels)\n",
    "    t1 = time.time() - t\n",
    "    t = time.time()\n",
    "    pr_lbls = clf.predict(data_test)\n",
    "    t2 = time.time() - t\n",
    "    return get_metrics(test_labels, pr_lbls) + (t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autolabels(rects, ax, time = False):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        if (time):\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                    '%f' % float(height) + \"s\",\n",
    "                  ha='center', va='bottom')\n",
    "        else:\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                    '%d' % int(height * 100) + \"%\",\n",
    "                  ha='center', va='bottom')\n",
    "\n",
    "def plot_results(labels, results, plot_label):\n",
    "    ind = np.arange(len(labels))  # the x locations for the groups\n",
    "    \n",
    "    width = 0.18    # the width of the bars\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(ind , results[:,0], width, color='g')\n",
    "    rects2 = ax.bar(ind - width, results[:,1], width, color='r')\n",
    "    rects3 = ax.bar(ind + width, results[:,2], width, color='b')\n",
    "    rects4 = ax.bar(ind + 2 * width, results[:,3], width, color='y')\n",
    "    \n",
    "    # add some text for labels, title and axes ticks\n",
    "    ax.set_ylim(0,1.4)\n",
    "    ax.set_ylabel('Percent')\n",
    "    ax.set_title('performance on: ' + plot_label)\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels(labels, rotation = 'horizontal')\n",
    "    ax.legend((rects1[0], rects2[0], rects3[0], rects4[0]), ('precision', 'recall', 'accuracy', 'F1 score'), bbox_to_anchor=(1.3,1), loc=\"upper right\")\n",
    "    \n",
    "    autolabels(rects1, ax)\n",
    "    autolabels(rects2, ax)\n",
    "    autolabels(rects3, ax)\n",
    "    autolabels(rects4, ax)\n",
    "    plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "    plt.savefig(img_dir + plot_label + \"-perf.png\", bbox_inches=\"tight\")\n",
    "    \n",
    "def plot_time(labels, time_exec, plot_label):\n",
    "    ind = np.arange(len(labels))  # the x locations for the groups\n",
    "    width = 0.35    # the width of the bars\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(ind - width / 2, time_exec[:, 0], width, color='b')\n",
    "    rects2 = ax.bar(ind + width / 2, time_exec[:, 1], width, color='r')\n",
    "    \n",
    "    # add some text for labels, title and axes ticks\n",
    "    ax.set_ylim(0, time_exec.max() * 1.2)\n",
    "    ax.set_ylabel('Time (s)')\n",
    "    ax.set_title('execution time on: ' + plot_label)\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(labels, rotation = 'horizontal')\n",
    "    ax.legend((rects1[0], rects2[0]), ('train time', 'test time'), bbox_to_anchor=(1.3,1), loc=\"upper right\")\n",
    "    \n",
    "    autolabels(rects1, ax, time = True)\n",
    "    plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "    \n",
    "    plt.savefig(img_dir + plot_label + \"-time.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(clfs, data, dataset_label):\n",
    "    results = []\n",
    "    train_data = data['train_data']\n",
    "    train_labels = data['train_labels']\n",
    "    test_data = data['test_data']\n",
    "    test_labels = data['test_labels']\n",
    "    for clf, name in clfs:\n",
    "        results.append(validate_performance(clf, train_data, train_labels, test_data, test_labels))\n",
    "    results = np.array(results)\n",
    "    plot_results(clfs[:, 1], np.array(results[:, :4]), dataset_label)\n",
    "    plot_time(clfs[:, 1], np.array(results[:, 4:]), dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = get_data(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = np.array([\n",
    "    [skl_svm.LinearSVC(random_state=0), 'SVM'],\n",
    "    [skl_lm.LogisticRegression(), 'Max Entropy'],\n",
    "    [skl_nb.MultinomialNB(alpha=.01), \"Multinomial NB\"],\n",
    "    [skl_nb.BernoulliNB(alpha=.01), \"BernoulliNB\"],\n",
    "    [skl_lm.RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"],\n",
    "    [skl_lm.Perceptron(max_iter=50), \"Perceptron\"], \n",
    "    [skl_lm.PassiveAggressiveClassifier(max_iter=50), \"Passive-Aggressive\"],\n",
    "    [skl_nei.KNeighborsClassifier(n_neighbors=10), \"kNN\"],\n",
    "    [skl_en.RandomForestClassifier(n_estimators=100), \"Random Forest\"]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-3190a0bcf3c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-6ab35b14aca4>\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(clfs, data, dataset_label)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ca6b37b324bd>\u001b[0m in \u001b[0;36mvalidate_performance\u001b[0;34m(clf, data_train, train_labels, data_test, test_labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    851\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[1;32m    852\u001b[0m                              \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mclass_weight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "for dataset_label in all_data:\n",
    "    benchmark(clfs, all_data[dataset_label], dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
