{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/cjhutto/vaderSentiment\n",
    "    \n",
    "Utilisation du fichier vader_lexicon.txt pour calculer la pos/neg/neu d'un tweet.\n",
    "Ce fichier a été crée \"à la main\" en demandant à plusieurs personnes de donner leur sentiment autour des mots proposés.\n",
    "Avantage: bonne accuracy des résultats\n",
    "Inconvénient: ne connait pas beaucoup de mot: classe beaucoup de tweet en neutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import sys\n",
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def get_tweet_sentiment(tweet):\n",
    "        '''\n",
    "        Utility function to classify sentiment of passed tweet\n",
    "        using textblob's sentiment method\n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text\n",
    "        analysis = TextBlob(clean_tweet(tweet))\n",
    "        # set sentiment\n",
    "        return analysis.sentiment.polarity\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "        \n",
    "def getDataLines(file_path):\n",
    "    f = open(file_path, \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close\n",
    "    return lines\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def get_tweet_sentiment(tweet):\n",
    "        '''\n",
    "        Utility function to classify sentiment of passed tweet\n",
    "        using textblob's sentiment method\n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text\n",
    "        analysis = TextBlob(clean_tweet(tweet))\n",
    "        # set sentiment\n",
    "        return analysis.sentiment.polarity\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8401940835811551\n"
     ]
    }
   ],
   "source": [
    "path = \"../../data/michigan/training.txt\"\n",
    "lines = getDataLines(path)\n",
    "\n",
    "count  = 0\n",
    "acc = 0\n",
    "\n",
    "for l in lines:\n",
    "    l = l.split(\"\\t\")\n",
    "    l[1] = l[1][:-1]\n",
    "    feeling = get_tweet_sentiment(l[1])\n",
    "    if (feeling != 0):\n",
    "        count = count + 1\n",
    "        if ((feeling > 0 and int(l[0]) == 1) or (feeling < 0 and int(l[0]) == 0)):\n",
    "            acc = acc + 1\n",
    "    \n",
    "print(acc/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data Positif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8372452927521279\n"
     ]
    }
   ],
   "source": [
    "path = \"../../data/michigan/training.txt\"\n",
    "lines = getDataLines(path)\n",
    "\n",
    "count  = 0\n",
    "acc = 0\n",
    "\n",
    "for l in lines:\n",
    "    l = l.split(\"\\t\")\n",
    "    l[1] = l[1][:-1]\n",
    "    feeling = get_tweet_sentiment(l[1])\n",
    "    if (feeling != 0 and int(l[0]) == 1):\n",
    "        count = count + 1\n",
    "        if (feeling > 0):\n",
    "            acc = acc + 1\n",
    "    \n",
    "print(acc/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data Negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8447452229299363\n"
     ]
    }
   ],
   "source": [
    "path = \"../../data/michigan/training.txt\"\n",
    "lines = getDataLines(path)\n",
    "\n",
    "count  = 0\n",
    "acc = 0\n",
    "\n",
    "for l in lines:\n",
    "    l = l.split(\"\\t\")\n",
    "    l[1] = l[1][:-1]\n",
    "    feeling = get_tweet_sentiment(l[1])\n",
    "    if (feeling != 0 and int(l[0]) == 0):\n",
    "        count = count + 1\n",
    "        if (feeling < 0):\n",
    "            acc = acc + 1\n",
    "    \n",
    "print(acc/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos: 17581\n",
      "Neg: 10599\n"
     ]
    }
   ],
   "source": [
    "path = \"../../data/michigan/testdata.txt\"\n",
    "lines = getDataLines(path)\n",
    "\n",
    "neg = 0\n",
    "pos = 0\n",
    "\n",
    "for l in lines:\n",
    "    feeling = get_tweet_sentiment(l)\n",
    "    if (feeling != 0):\n",
    "        count = count + 1\n",
    "        if (feeling > 0):\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "            \n",
    "    \n",
    "print(\"Pos:\", pos)\n",
    "print(\"Neg:\", neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c4802cb4580a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from vaderSentiment import sentiment\n",
    "path = \"../data/michigan/training.txt\"\n",
    "lines = getDataLines(path)\n",
    "\n",
    "\n",
    "count = 0\n",
    "acc = 0\n",
    "n = 0\n",
    "for l in lines:\n",
    "    l = l.split(\"\\t\")\n",
    "    l[1] = l[1][:-1]\n",
    "    sent = sentiment(l[1])\n",
    "    pos = float(sent['pos'])\n",
    "    neg = float(sent['neg'])\n",
    "    neu = float(sent['neu'])\n",
    "    if (neu != 1):\n",
    "        count += 1\n",
    "        if ((int(l[0]) == 1 and pos > neg) or (int(l[0]) == 0 and neg > pos)):\n",
    "            acc += 1\n",
    "    else:\n",
    "        feel = get_tweet_sentiment(l[1])\n",
    "        if (feel != 0):\n",
    "            count += 1\n",
    "            if ((int(l[0]) == 1 and feel > 0) or (int(l[0]) == 0 and feel < 0)):\n",
    "                acc += 1\n",
    "        else:\n",
    "            n += 1\n",
    "\n",
    "    \n",
    "print(acc/count, \"% accuracy\")\n",
    "print(count, \"tweets étudiés\")\n",
    "print(n, \"tweets neutres\")\n",
    "print(count/len(lines), \"% des tweets utilisés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "L'accuracy est de 100% dans le cas où on filtre les cas où pos ou neg est > 0.5\n",
    "Si on filtre les neutre qui le sont à 1 alors on obtient une accuracy de 90%\n",
    "Dans le cas normal, accuracy est de 80%\n",
    "\n",
    "Si on utilise textblob dans le cas où le tweet est considéré comme neutre, alors on obtient 86% d'accuracy.\n",
    "Si on ignore encore les tweet considéré comme neutre par vader ET textblob alors on obtient un accuracy de 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOP debate Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4494268617979958 % accuracy\n",
      "13871 tweets étudiés\n",
      "3060 tweets neutres\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from vaderSentiment import sentiment\n",
    "path = \"../../data/first-gop-debate-twitter-sentiment/Sentiment.csv\"\n",
    "\n",
    "\n",
    "file = open(path, \"r\")\n",
    "lines = [(l[5], l[15]) for l in csv.reader(file)][1:]\n",
    "\n",
    "count = 0\n",
    "acc = 0\n",
    "n = 0\n",
    "for l in lines:\n",
    "    sent = sentiment(l[1])\n",
    "    pos = float(sent['pos'])\n",
    "    neg = float(sent['neg'])\n",
    "    neu = float(sent['neu'])\n",
    "    if (neu == 1):\n",
    "        feel = get_tweet_sentiment(l[1])\n",
    "        if feel == 0:\n",
    "            sent = \"Neutral\"\n",
    "            n += 1\n",
    "        elif feel > 1:\n",
    "            sent = \"Positive\"\n",
    "        else:\n",
    "            sent = \"Negative\"\n",
    "        \n",
    "    elif pos > neg:\n",
    "        sent = \"Positive\"\n",
    "    else:\n",
    "        sent = \"Negative\"\n",
    "\n",
    "    if (l[0] == sent):\n",
    "        acc += 1\n",
    "    count += 1\n",
    "    \n",
    "print(acc/count, \"% accuracy\")\n",
    "print(count, \"tweets étudiés\")\n",
    "print(n, \"tweets neutres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airline tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from vaderSentiment import sentiment\n",
    "path = \"../../data/twitter-airline-sentiment/Tweets.csv\"\n",
    "\n",
    "\n",
    "file = open(path, \"r\")\n",
    "lines = [(l[5], l[15]) for l in csv.reader(file)][1:]\n",
    "\n",
    "count = 0\n",
    "acc = 0\n",
    "n = 0\n",
    "for l in lines:\n",
    "    sent = sentiment(l[1])\n",
    "    pos = float(sent['pos'])\n",
    "    neg = float(sent['neg'])\n",
    "    neu = float(sent['neu'])\n",
    "    if (neu == 1):\n",
    "        feel = get_tweet_sentiment(l[1])\n",
    "        if feel == 0:\n",
    "            sent = \"neutral\"\n",
    "            n += 1\n",
    "        elif feel > 1:\n",
    "            sent = \"positive\"\n",
    "        else:\n",
    "            sent = \"negative\"\n",
    "        \n",
    "    elif pos > neg:\n",
    "        sent = \"positive\"\n",
    "    else:\n",
    "        sent = \"negative\"\n",
    "\n",
    "    if (l[0] == sent):\n",
    "        acc += 1\n",
    "    count += 1\n",
    "    \n",
    "print(acc/count, \"% accuracy\")\n",
    "print(count, \"tweets étudiés\")\n",
    "print(n, \"tweets neutres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5234289617486338 % accuracy\n",
      "14640 tweets étudiés\n",
      "5534 tweets neutres\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from vaderSentiment import sentiment\n",
    "path = \"../../data/twitter-airline-sentiment/Tweets.csv\"\n",
    "\n",
    "\n",
    "file = open(path, \"r\")\n",
    "lines = [(l[1], l[10]) for l in csv.reader(file)][1:]\n",
    "\n",
    "count = 0\n",
    "acc = 0\n",
    "n = 0\n",
    "\n",
    "for l in lines:\n",
    "    sent = \"\"\n",
    "    feel = get_tweet_sentiment(l[1])\n",
    "    if feel == 0:\n",
    "        sent = \"neutral\"\n",
    "        n += 1\n",
    "    elif feel > 1:\n",
    "        sent = \"positive\"\n",
    "    else:\n",
    "        sent = \"negative\"\n",
    "    count += 1\n",
    "    if (l[0] == sent):\n",
    "        acc += 1\n",
    "\n",
    "    \n",
    "\n",
    "print(acc/count, \"% accuracy\")\n",
    "print(count, \"tweets étudiés\")\n",
    "print(n, \"tweets neutres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import vaderSentiment\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "files = [\"../../data/data_cleaned/labelised/airline.txt\",\n",
    "\"../../data/data_cleaned/labelised/hutto.txt\",\n",
    "\"../../data/data_cleaned/labelised/kaggle.txt\",\n",
    "\"../../data/data_cleaned/labelised/michigan.txt\",\n",
    "\"../../data/data_cleaned/labelised/rt-polarity-neg.txt\",\n",
    "\"../../data/data_cleaned/labelised/rt-polarity-pos.txt\"]\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def get_sentiment(tweet):\n",
    "        analysis = TextBlob(clean_tweet(tweet))\n",
    "        return analysis.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/data_cleaned/labelised/airline.txt\n",
      "Neutral (don't know ?) : 3769 (32.65748202062213%)\n",
      "Accuracy               : 64.01183736489963%\n",
      "Precision              : 39.63620031439479%\n",
      "Recall                 : 94.18356456776948%\n",
      "F1 score               : 55.79263474000315%\n",
      "../../data/data_cleaned/labelised/hutto.txt\n",
      "Neutral (don't know ?) : 3965 (19.936645213193884%)\n",
      "Accuracy               : 70.46410852226339%\n",
      "Precision              : 67.93906810035843%\n",
      "Recall                 : 87.07936143332951%\n",
      "F1 score               : 76.32757839633562%\n",
      "../../data/data_cleaned/labelised/kaggle.txt\n",
      "Neutral (don't know ?) : 11 (0.044%)\n",
      "Accuracy               : 68.90631878026332%\n",
      "Precision              : 62.47689463955638%\n",
      "Recall                 : 94.67787114845937%\n",
      "F1 score               : 75.27839643652563%\n",
      "../../data/data_cleaned/labelised/michigan.txt\n",
      "Neutral (don't know ?) : 697 (9.83629692351115%)\n",
      "Accuracy               : 84.01940835811551%\n",
      "Precision              : 89.27392739273927%\n",
      "Recall                 : 83.72452927521279%\n",
      "F1 score               : 86.41022228137895%\n",
      "../../data/data_cleaned/labelised/rt-polarity-neg.txt\n",
      "Neutral (don't know ?) : 826 (15.49427874695179%)\n",
      "Accuracy               : 46.59267480577137%\n",
      "Precision              : 0.0%\n",
      "Recall                 : 0%\n",
      "F1 score               : 0%\n",
      "../../data/data_cleaned/labelised/rt-polarity-pos.txt\n",
      "Neutral (don't know ?) : 713 (13.374601388107298%)\n",
      "Accuracy               : 82.65482893027286%\n",
      "Precision              : 100.0%\n",
      "Recall                 : 82.65482893027286%\n",
      "F1 score               : 90.50385299347955%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for f in files:\n",
    "    print(f)\n",
    "    f = open(f, \"r\")\n",
    "    lines = json.loads(f.readlines()[0])\n",
    "    \n",
    "    count  = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "\n",
    "    dont_know = 0\n",
    "    for l in lines:\n",
    "        feeling = get_sentiment(l[1])\n",
    "        if (feeling == 0):\n",
    "            dont_know = dont_know + 1\n",
    "        else:\n",
    "            label = l[0]\n",
    "            if (feeling > 0):\n",
    "                if (label == 1):\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "            else:\n",
    "                if (label == 0):\n",
    "                    tn += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "        count = count + 1\n",
    "        #if (count % 10 == 0) :\n",
    "        #    print(count)\n",
    "\n",
    "    print(\"Neutral (don't know ?) : \" + str(dont_know) + \" (\"  + str(100 * float(dont_know) / float(count)) + \"%)\")\n",
    "    if (tp + tn + fp + fn):\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    else:\n",
    "        accuracy = 0\n",
    "    print(\"Accuracy               : \" + str(100 * accuracy) + \"%\")\n",
    "    if (tp + fp):\n",
    "        precision = tp / (tp + fp)\n",
    "    else:\n",
    "        precision = 0\n",
    "    print(\"Precision              : \" + str(100 * precision) + \"%\")\n",
    "    if (tp + fn):\n",
    "        recall = tp / (tp + fn)\n",
    "    else:\n",
    "        recall = 0\n",
    "    print(\"Recall                 : \" + str(100 * recall) + \"%\")\n",
    "    if (recall and precision):\n",
    "        f1 = 2 / ((1/recall) + (1/precision))\n",
    "    else:\n",
    "        f1 = 0\n",
    "    print(\"F1 score               : \" + str(100 * f1) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
